{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a112b447-698e-4804-8d64-b7dbe3a51df2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-12-08 13:34:42.247359: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from neuralnetworks import ffnn, embedding, attention, masking, transformer\n",
    "from tokenization import tokenizer\n",
    "import importlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9fb0dc1c-237f-46b0-8664-937cb130e966",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "256"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "size = 2**8\n",
    "\n",
    "size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5922be05-ffd3-4f98-bfac-f11ffebca41a",
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding = embedding.EmbeddingLayer(size, name = \"embedding\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "80532cfd-0bfa-4908-9ebe-7527a89fb47f",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_string = \"the cow jumped over the moon\"\n",
    "\n",
    "tkn = tokenizer.Tokenizer()\n",
    "\n",
    "tkn(input_string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2a70a10b-e9dd-41a0-9446-e09df0056e94",
   "metadata": {},
   "outputs": [],
   "source": [
    "for t in tkn.token_q:\n",
    "    embedding(t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "1274b8fe-5745-4ef8-b54b-16074ecf7858",
   "metadata": {},
   "outputs": [],
   "source": [
    "#this is where positional encoding should happen\n",
    "\n",
    "batch = tf.expand_dims(embedding.embeddings, axis = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "901be2b7-7df8-4602-a147-866b4f28720a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{1: <neuralnetworks.transformer.TransformerLayer at 0x16136f940>,\n",
       " 2: <neuralnetworks.transformer.TransformerLayer at 0x161c6eeb0>,\n",
       " 3: <neuralnetworks.transformer.TransformerLayer at 0x161c7dcd0>,\n",
       " 4: <neuralnetworks.transformer.TransformerLayer at 0x161c8eaf0>,\n",
       " 5: <neuralnetworks.transformer.TransformerLayer at 0x161c9e910>,\n",
       " 6: <neuralnetworks.transformer.TransformerLayer at 0x161cad730>,\n",
       " 7: <neuralnetworks.transformer.TransformerLayer at 0x161cbc550>,\n",
       " 8: <neuralnetworks.transformer.TransformerLayer at 0x161cce3a0>,\n",
       " 9: <neuralnetworks.transformer.TransformerLayer at 0x161cdf1c0>,\n",
       " 10: <neuralnetworks.transformer.TransformerLayer at 0x161ce9fa0>,\n",
       " 11: <neuralnetworks.transformer.TransformerLayer at 0x161cf8dc0>,\n",
       " 12: <neuralnetworks.transformer.TransformerLayer at 0x161d08be0>,\n",
       " 13: <neuralnetworks.transformer.TransformerLayer at 0x161d19a00>,\n",
       " 14: <neuralnetworks.transformer.TransformerLayer at 0x161d29820>,\n",
       " 15: <neuralnetworks.transformer.TransformerLayer at 0x161d3b640>,\n",
       " 16: <neuralnetworks.transformer.TransformerLayer at 0x161d4a460>,\n",
       " 17: <neuralnetworks.transformer.TransformerLayer at 0x161d5a280>,\n",
       " 18: <neuralnetworks.transformer.TransformerLayer at 0x161d6d0a0>,\n",
       " 19: <neuralnetworks.transformer.TransformerLayer at 0x161d78e80>,\n",
       " 20: <neuralnetworks.transformer.TransformerLayer at 0x161d87ca0>,\n",
       " 21: <neuralnetworks.transformer.TransformerLayer at 0x161d98ac0>,\n",
       " 22: <neuralnetworks.transformer.TransformerLayer at 0x161da88e0>,\n",
       " 23: <neuralnetworks.transformer.TransformerLayer at 0x161db8700>,\n",
       " 24: <neuralnetworks.transformer.TransformerLayer at 0x161dca520>,\n",
       " 25: <neuralnetworks.transformer.TransformerLayer at 0x161dd9340>,\n",
       " 26: <neuralnetworks.transformer.TransformerLayer at 0x161dea160>,\n",
       " 27: <neuralnetworks.transformer.TransformerLayer at 0x161df5f40>,\n",
       " 28: <neuralnetworks.transformer.TransformerLayer at 0x161e06d60>,\n",
       " 29: <neuralnetworks.transformer.TransformerLayer at 0x161e16b80>,\n",
       " 30: <neuralnetworks.transformer.TransformerLayer at 0x161e279a0>,\n",
       " 31: <neuralnetworks.transformer.TransformerLayer at 0x161e367c0>,\n",
       " 32: <neuralnetworks.transformer.TransformerLayer at 0x161e465e0>}"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "importlib.reload(attention)\n",
    "\n",
    "tfmrs = {}\n",
    "\n",
    "for i in range (1,33):\n",
    "    tfmrs = {**tfmrs, **{i: transformer.TransformerLayer(size, batch.shape[1], 4 , 4*size)}}\n",
    "\n",
    "tfmrs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "7fff2833-4180-4854-b35a-89a2fd16ff9a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(1, 5, 256), dtype=float32, numpy=\n",
       "array([[[-0.09947905,  0.72585285,  0.05796956, ...,  0.47017947,\n",
       "         -0.29539815, -1.2876405 ],\n",
       "        [-0.63762605,  0.25631022, -0.8624704 , ...,  1.2280862 ,\n",
       "         -1.3891668 , -0.55693626],\n",
       "        [-0.1854893 ,  0.40731052, -0.89137244, ...,  1.1436095 ,\n",
       "         -0.71106625, -0.28736824],\n",
       "        [-0.5650112 ,  0.6678289 , -0.3698084 , ...,  1.2423675 ,\n",
       "          0.76084447, -0.5305328 ],\n",
       "        [ 0.07580578,  0.43767974,  0.18874934, ...,  1.1018841 ,\n",
       "         -0.23056355, -0.42522687]]], dtype=float32)>"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for i in range(1,33):\n",
    "    batch = tfmrs[i](batch)\n",
    "\n",
    "batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "9f375938-a871-4541-bd4f-5c734e99f7d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TransformerFinalLayer(tf.keras.layers.Layer):\n",
    "    def __init__(self, vocab_size, d_model):\n",
    "        super(TransformerFinalLayer, self).__init__()\n",
    "        self.projection = tf.keras.layers.Dense(vocab_size)\n",
    "\n",
    "    def __call__(self, inputs):\n",
    "        logits = self.projection(inputs)  # Project to vocab_size\n",
    "        probabilities = tf.nn.softmax(logits, axis=-1)  # Convert to probabilities\n",
    "        return probabilities\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "cc78903e-b0b0-44b4-b8c3-33d8c96b7847",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_layer = TransformerFinalLayer(10, batch.shape[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "26a36908-8368-4f2c-a87e-f0f27c19ab90",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(1, 5, 10), dtype=float32, numpy=\n",
       "array([[[0.03044865, 0.01383561, 0.20512821, 0.01574093, 0.1889186 ,\n",
       "         0.03273387, 0.04645465, 0.22605082, 0.1199559 , 0.12073276],\n",
       "        [0.02632543, 0.02578001, 0.2321132 , 0.09279155, 0.27085042,\n",
       "         0.0603786 , 0.14260237, 0.05851465, 0.02639292, 0.06425083],\n",
       "        [0.15056264, 0.03874962, 0.17088121, 0.06529535, 0.13705961,\n",
       "         0.07896155, 0.09057087, 0.10327346, 0.06807107, 0.09657457],\n",
       "        [0.04188018, 0.06694464, 0.08726914, 0.04041603, 0.15776102,\n",
       "         0.03249858, 0.07331317, 0.10460029, 0.15982619, 0.2354908 ],\n",
       "        [0.0265914 , 0.1450832 , 0.04418058, 0.21870838, 0.111321  ,\n",
       "         0.13693565, 0.03594118, 0.04137687, 0.15984032, 0.08002143]]],\n",
       "      dtype=float32)>"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_layer(batch)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "417d98d3-d462-4a95-90bf-021630ff90d2",
   "metadata": {},
   "source": [
    "# Vocabulary Initialization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "0b493589-2ddc-4b8f-9c28-e1a25894415a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['#define', '#include', '#if', '#else', '#endif', 'auto', 'break', 'case', 'char', 'const', 'continue', 'default', 'do', 'double', 'else', 'enum', 'extern', 'float', 'for', 'goto', 'if', 'int', 'long', 'register', 'return', 'short', 'signed', 'sizeof', 'static', 'struct', 'switch', 'typedef', 'union', 'unsigned', 'void', 'volatile', 'while', '_Bool', '_Complex', '_Imaginary', 'inline', 'restrict', '_Alignas', '_Alignof', '_Atomic', '_Generic', '_Noreturn', '_Static_assert', '_Thread_local', '+', '-', '*', '/', '%', '==', '!=', '>', '<', '>=', '<=', '&&', '||', '!', '&', '|', '^', '~', '<<', '>>', '++', '--', '*', '&', 'sizeof', '?:', ',', '.', '->', '%int', '%var', '%float', '%string', '%func', '%class', ';', '{', '}', '{}', '']\n"
     ]
    }
   ],
   "source": [
    "with open(\"/Users/joericks/Desktop/nova/model/constants/vocabulary.txt\", \"r\") as f:\n",
    "    vocab = f.read().split('\\n')\n",
    "    print(vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "f473304b-c3e2-4385-beb8-ffb93a889de8",
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab_size = len(vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "d1b563c0-f28d-4926-8db5-159ce9b6ecfd",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_final_layer = TransformerFinalLayer(vocab_size, batch.shape[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "1868aa08-2db1-48e2-bf39-4b7315c7b7f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def mean(arr):\n",
    "    return sum([i*arr[i] for i in range(0, len(arr))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "2bf14b32-99aa-4db1-84c2-252b912be792",
   "metadata": {},
   "outputs": [],
   "source": [
    "final = new_final_layer(batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "fbd946cb-854a-4297-b522-da923811a454",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(43.136044, shape=(), dtype=float32)\n",
      "tf.Tensor(40.895535, shape=(), dtype=float32)\n",
      "tf.Tensor(43.852276, shape=(), dtype=float32)\n",
      "tf.Tensor(43.80238, shape=(), dtype=float32)\n",
      "tf.Tensor(43.360542, shape=(), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "means = []\n",
    "\n",
    "for i in range(final.shape[0]):\n",
    "    for j in range(final.shape[1]):\n",
    "        print(mean(final[i,j]))\n",
    "        means.append(mean(final[i,j]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "929d1d75-aeb4-45ed-a670-3f854baba839",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<tf.Tensor: shape=(), dtype=float32, numpy=45.7917>,\n",
       " <tf.Tensor: shape=(), dtype=float32, numpy=43.750305>,\n",
       " <tf.Tensor: shape=(), dtype=float32, numpy=46.327908>,\n",
       " <tf.Tensor: shape=(), dtype=float32, numpy=46.486794>,\n",
       " <tf.Tensor: shape=(), dtype=float32, numpy=45.664543>]"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "means"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a112b447-698e-4804-8d64-b7dbe3a51df2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-12-08 13:34:42.247359: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from neuralnetworks import ffnn, embedding, attention, masking, transformer\n",
    "from tokenization import tokenizer\n",
    "import importlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9fb0dc1c-237f-46b0-8664-937cb130e966",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "256"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "size = 2**8\n",
    "\n",
    "size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5922be05-ffd3-4f98-bfac-f11ffebca41a",
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding = embedding.EmbeddingLayer(size, name = \"embedding\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "80532cfd-0bfa-4908-9ebe-7527a89fb47f",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_string = \"the cow jumped over the moon\"\n",
    "\n",
    "tkn = tokenizer.Tokenizer()\n",
    "\n",
    "tkn(input_string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2a70a10b-e9dd-41a0-9446-e09df0056e94",
   "metadata": {},
   "outputs": [],
   "source": [
    "for t in tkn.token_q:\n",
    "    embedding(t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "1274b8fe-5745-4ef8-b54b-16074ecf7858",
   "metadata": {},
   "outputs": [],
   "source": [
    "#this is where positional encoding should happen\n",
    "\n",
    "batch = tf.expand_dims(embedding.embeddings, axis = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "901be2b7-7df8-4602-a147-866b4f28720a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{1: <neuralnetworks.transformer.TransformerLayer at 0x16136f940>,\n",
       " 2: <neuralnetworks.transformer.TransformerLayer at 0x161c6eeb0>,\n",
       " 3: <neuralnetworks.transformer.TransformerLayer at 0x161c7dcd0>,\n",
       " 4: <neuralnetworks.transformer.TransformerLayer at 0x161c8eaf0>,\n",
       " 5: <neuralnetworks.transformer.TransformerLayer at 0x161c9e910>,\n",
       " 6: <neuralnetworks.transformer.TransformerLayer at 0x161cad730>,\n",
       " 7: <neuralnetworks.transformer.TransformerLayer at 0x161cbc550>,\n",
       " 8: <neuralnetworks.transformer.TransformerLayer at 0x161cce3a0>,\n",
       " 9: <neuralnetworks.transformer.TransformerLayer at 0x161cdf1c0>,\n",
       " 10: <neuralnetworks.transformer.TransformerLayer at 0x161ce9fa0>,\n",
       " 11: <neuralnetworks.transformer.TransformerLayer at 0x161cf8dc0>,\n",
       " 12: <neuralnetworks.transformer.TransformerLayer at 0x161d08be0>,\n",
       " 13: <neuralnetworks.transformer.TransformerLayer at 0x161d19a00>,\n",
       " 14: <neuralnetworks.transformer.TransformerLayer at 0x161d29820>,\n",
       " 15: <neuralnetworks.transformer.TransformerLayer at 0x161d3b640>,\n",
       " 16: <neuralnetworks.transformer.TransformerLayer at 0x161d4a460>,\n",
       " 17: <neuralnetworks.transformer.TransformerLayer at 0x161d5a280>,\n",
       " 18: <neuralnetworks.transformer.TransformerLayer at 0x161d6d0a0>,\n",
       " 19: <neuralnetworks.transformer.TransformerLayer at 0x161d78e80>,\n",
       " 20: <neuralnetworks.transformer.TransformerLayer at 0x161d87ca0>,\n",
       " 21: <neuralnetworks.transformer.TransformerLayer at 0x161d98ac0>,\n",
       " 22: <neuralnetworks.transformer.TransformerLayer at 0x161da88e0>,\n",
       " 23: <neuralnetworks.transformer.TransformerLayer at 0x161db8700>,\n",
       " 24: <neuralnetworks.transformer.TransformerLayer at 0x161dca520>,\n",
       " 25: <neuralnetworks.transformer.TransformerLayer at 0x161dd9340>,\n",
       " 26: <neuralnetworks.transformer.TransformerLayer at 0x161dea160>,\n",
       " 27: <neuralnetworks.transformer.TransformerLayer at 0x161df5f40>,\n",
       " 28: <neuralnetworks.transformer.TransformerLayer at 0x161e06d60>,\n",
       " 29: <neuralnetworks.transformer.TransformerLayer at 0x161e16b80>,\n",
       " 30: <neuralnetworks.transformer.TransformerLayer at 0x161e279a0>,\n",
       " 31: <neuralnetworks.transformer.TransformerLayer at 0x161e367c0>,\n",
       " 32: <neuralnetworks.transformer.TransformerLayer at 0x161e465e0>}"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "importlib.reload(attention)\n",
    "\n",
    "tfmrs = {}\n",
    "\n",
    "for i in range (1,33):\n",
    "    tfmrs = {**tfmrs, **{i: transformer.TransformerLayer(size, batch.shape[1], 4 , 4*size)}}\n",
    "\n",
    "tfmrs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "7fff2833-4180-4854-b35a-89a2fd16ff9a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(1, 5, 256), dtype=float32, numpy=\n",
       "array([[[-0.09947905,  0.72585285,  0.05796956, ...,  0.47017947,\n",
       "         -0.29539815, -1.2876405 ],\n",
       "        [-0.63762605,  0.25631022, -0.8624704 , ...,  1.2280862 ,\n",
       "         -1.3891668 , -0.55693626],\n",
       "        [-0.1854893 ,  0.40731052, -0.89137244, ...,  1.1436095 ,\n",
       "         -0.71106625, -0.28736824],\n",
       "        [-0.5650112 ,  0.6678289 , -0.3698084 , ...,  1.2423675 ,\n",
       "          0.76084447, -0.5305328 ],\n",
       "        [ 0.07580578,  0.43767974,  0.18874934, ...,  1.1018841 ,\n",
       "         -0.23056355, -0.42522687]]], dtype=float32)>"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for i in range(1,33):\n",
    "    batch = tfmrs[i](batch)\n",
    "\n",
    "batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "9f375938-a871-4541-bd4f-5c734e99f7d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TransformerFinalLayer(tf.keras.layers.Layer):\n",
    "    def __init__(self, vocab_size, d_model):\n",
    "        super(TransformerFinalLayer, self).__init__()\n",
    "        self.projection = tf.keras.layers.Dense(vocab_size)\n",
    "\n",
    "    def __call__(self, inputs):\n",
    "        logits = self.projection(inputs)  # Project to vocab_size\n",
    "        probabilities = tf.nn.softmax(logits, axis=-1)  # Convert to probabilities\n",
    "        return probabilities\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "cc78903e-b0b0-44b4-b8c3-33d8c96b7847",
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab_size = 10000\n",
    "\n",
    "final_layer = TransformerFinalLayer(vocab_size, batch.shape[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "26a36908-8368-4f2c-a87e-f0f27c19ab90",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(1, 5, 10000), dtype=float32, numpy=\n",
       "array([[[9.50720641e-05, 1.01481455e-04, 9.96293529e-05, ...,\n",
       "         1.02589183e-04, 1.06176216e-04, 8.45819450e-05],\n",
       "        [1.20231263e-04, 1.03113452e-04, 9.67519009e-05, ...,\n",
       "         1.04702078e-04, 9.98386022e-05, 1.10322078e-04],\n",
       "        [1.09680972e-04, 1.01030098e-04, 9.88786996e-05, ...,\n",
       "         1.08496897e-04, 9.98210744e-05, 1.03300583e-04],\n",
       "        [8.34702587e-05, 8.84053443e-05, 1.03564889e-04, ...,\n",
       "         1.02230777e-04, 9.24306223e-05, 9.38480152e-05],\n",
       "        [9.26171269e-05, 8.91744567e-05, 1.40545933e-04, ...,\n",
       "         9.83482751e-05, 1.00042795e-04, 9.38134326e-05]]], dtype=float32)>"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_layer(batch)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "417d98d3-d462-4a95-90bf-021630ff90d2",
   "metadata": {},
   "source": [
    "# Vocabulary Initialization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "0b493589-2ddc-4b8f-9c28-e1a25894415a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['#define', '#include', '#if', '#else', '#endif', 'auto', 'break', 'case', 'char', 'const', 'continue', 'default', 'do', 'double', 'else', 'enum', 'extern', 'float', 'for', 'goto', 'if', 'int', 'long', 'register', 'return', 'short', 'signed', 'sizeof', 'static', 'struct', 'switch', 'typedef', 'union', 'unsigned', 'void', 'volatile', 'while', '_Bool', '_Complex', '_Imaginary', 'inline', 'restrict', '_Alignas', '_Alignof', '_Atomic', '_Generic', '_Noreturn', '_Static_assert', '_Thread_local', '+', '-', '*', '/', '%', '==', '!=', '>', '<', '>=', '<=', '&&', '||', '!', '&', '|', '^', '~', '<<', '>>', '++', '--', '*', '&', 'sizeof', '?:', ',', '.', '->', '%int', '%var', '%float', '%string', '%func', '%class', ';', '{', '}', '{}', '']\n"
     ]
    }
   ],
   "source": [
    "with open(\"/Users/joericks/Desktop/nova/model/constants/vocabulary.txt\", \"r\") as f:\n",
    "    content = f.read().split('\\n')\n",
    "    print(content)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

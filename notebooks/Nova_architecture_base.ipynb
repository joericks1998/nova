{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a112b447-698e-4804-8d64-b7dbe3a51df2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-12-08 13:34:42.247359: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from neuralnetworks import ffnn, embedding, attention, masking, transformer\n",
    "from tokenization import tokenizer\n",
    "import importlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9fb0dc1c-237f-46b0-8664-937cb130e966",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "256"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "size = 2**8\n",
    "\n",
    "size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5922be05-ffd3-4f98-bfac-f11ffebca41a",
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding = embedding.EmbeddingLayer(size, name = \"embedding\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "80532cfd-0bfa-4908-9ebe-7527a89fb47f",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_string = \"the cow jumped over the moon\"\n",
    "\n",
    "tkn = tokenizer.Tokenizer()\n",
    "\n",
    "tkn(input_string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2a70a10b-e9dd-41a0-9446-e09df0056e94",
   "metadata": {},
   "outputs": [],
   "source": [
    "for t in tkn.token_q:\n",
    "    embedding(t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "1274b8fe-5745-4ef8-b54b-16074ecf7858",
   "metadata": {},
   "outputs": [],
   "source": [
    "#this is where positional encoding should happen\n",
    "\n",
    "batch = tf.expand_dims(embedding.embeddings, axis = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "901be2b7-7df8-4602-a147-866b4f28720a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{1: <neuralnetworks.transformer.TransformerLayer at 0x16136f940>,\n",
       " 2: <neuralnetworks.transformer.TransformerLayer at 0x161c6eeb0>,\n",
       " 3: <neuralnetworks.transformer.TransformerLayer at 0x161c7dcd0>,\n",
       " 4: <neuralnetworks.transformer.TransformerLayer at 0x161c8eaf0>,\n",
       " 5: <neuralnetworks.transformer.TransformerLayer at 0x161c9e910>,\n",
       " 6: <neuralnetworks.transformer.TransformerLayer at 0x161cad730>,\n",
       " 7: <neuralnetworks.transformer.TransformerLayer at 0x161cbc550>,\n",
       " 8: <neuralnetworks.transformer.TransformerLayer at 0x161cce3a0>,\n",
       " 9: <neuralnetworks.transformer.TransformerLayer at 0x161cdf1c0>,\n",
       " 10: <neuralnetworks.transformer.TransformerLayer at 0x161ce9fa0>,\n",
       " 11: <neuralnetworks.transformer.TransformerLayer at 0x161cf8dc0>,\n",
       " 12: <neuralnetworks.transformer.TransformerLayer at 0x161d08be0>,\n",
       " 13: <neuralnetworks.transformer.TransformerLayer at 0x161d19a00>,\n",
       " 14: <neuralnetworks.transformer.TransformerLayer at 0x161d29820>,\n",
       " 15: <neuralnetworks.transformer.TransformerLayer at 0x161d3b640>,\n",
       " 16: <neuralnetworks.transformer.TransformerLayer at 0x161d4a460>,\n",
       " 17: <neuralnetworks.transformer.TransformerLayer at 0x161d5a280>,\n",
       " 18: <neuralnetworks.transformer.TransformerLayer at 0x161d6d0a0>,\n",
       " 19: <neuralnetworks.transformer.TransformerLayer at 0x161d78e80>,\n",
       " 20: <neuralnetworks.transformer.TransformerLayer at 0x161d87ca0>,\n",
       " 21: <neuralnetworks.transformer.TransformerLayer at 0x161d98ac0>,\n",
       " 22: <neuralnetworks.transformer.TransformerLayer at 0x161da88e0>,\n",
       " 23: <neuralnetworks.transformer.TransformerLayer at 0x161db8700>,\n",
       " 24: <neuralnetworks.transformer.TransformerLayer at 0x161dca520>,\n",
       " 25: <neuralnetworks.transformer.TransformerLayer at 0x161dd9340>,\n",
       " 26: <neuralnetworks.transformer.TransformerLayer at 0x161dea160>,\n",
       " 27: <neuralnetworks.transformer.TransformerLayer at 0x161df5f40>,\n",
       " 28: <neuralnetworks.transformer.TransformerLayer at 0x161e06d60>,\n",
       " 29: <neuralnetworks.transformer.TransformerLayer at 0x161e16b80>,\n",
       " 30: <neuralnetworks.transformer.TransformerLayer at 0x161e279a0>,\n",
       " 31: <neuralnetworks.transformer.TransformerLayer at 0x161e367c0>,\n",
       " 32: <neuralnetworks.transformer.TransformerLayer at 0x161e465e0>}"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "importlib.reload(attention)\n",
    "\n",
    "tfmrs = {}\n",
    "\n",
    "for i in range (1,33):\n",
    "    tfmrs = {**tfmrs, **{i: transformer.TransformerLayer(size, batch.shape[1], 4 , 4*size)}}\n",
    "\n",
    "tfmrs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "7fff2833-4180-4854-b35a-89a2fd16ff9a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(1, 5, 256), dtype=float32, numpy=\n",
       "array([[[-0.09947905,  0.72585285,  0.05796956, ...,  0.47017947,\n",
       "         -0.29539815, -1.2876405 ],\n",
       "        [-0.63762605,  0.25631022, -0.8624704 , ...,  1.2280862 ,\n",
       "         -1.3891668 , -0.55693626],\n",
       "        [-0.1854893 ,  0.40731052, -0.89137244, ...,  1.1436095 ,\n",
       "         -0.71106625, -0.28736824],\n",
       "        [-0.5650112 ,  0.6678289 , -0.3698084 , ...,  1.2423675 ,\n",
       "          0.76084447, -0.5305328 ],\n",
       "        [ 0.07580578,  0.43767974,  0.18874934, ...,  1.1018841 ,\n",
       "         -0.23056355, -0.42522687]]], dtype=float32)>"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for i in range(1,33):\n",
    "    batch = tfmrs[i](batch)\n",
    "\n",
    "batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "9f375938-a871-4541-bd4f-5c734e99f7d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TransformerFinalLayer(tf.keras.layers.Layer):\n",
    "    def __init__(self, vocab_size, d_model):\n",
    "        super(TransformerFinalLayer, self).__init__()\n",
    "        self.projection = tf.keras.layers.Dense(vocab_size)\n",
    "\n",
    "    def __call__(self, inputs):\n",
    "        logits = self.projection(inputs)  # Project to vocab_size\n",
    "        probabilities = tf.nn.softmax(logits, axis=-1)  # Convert to probabilities\n",
    "        return probabilities\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "cc78903e-b0b0-44b4-b8c3-33d8c96b7847",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_layer = TransformerFinalLayer(10, batch.shape[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "26a36908-8368-4f2c-a87e-f0f27c19ab90",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(1, 5, 10), dtype=float32, numpy=\n",
       "array([[[0.03044865, 0.01383561, 0.20512821, 0.01574093, 0.1889186 ,\n",
       "         0.03273387, 0.04645465, 0.22605082, 0.1199559 , 0.12073276],\n",
       "        [0.02632543, 0.02578001, 0.2321132 , 0.09279155, 0.27085042,\n",
       "         0.0603786 , 0.14260237, 0.05851465, 0.02639292, 0.06425083],\n",
       "        [0.15056264, 0.03874962, 0.17088121, 0.06529535, 0.13705961,\n",
       "         0.07896155, 0.09057087, 0.10327346, 0.06807107, 0.09657457],\n",
       "        [0.04188018, 0.06694464, 0.08726914, 0.04041603, 0.15776102,\n",
       "         0.03249858, 0.07331317, 0.10460029, 0.15982619, 0.2354908 ],\n",
       "        [0.0265914 , 0.1450832 , 0.04418058, 0.21870838, 0.111321  ,\n",
       "         0.13693565, 0.03594118, 0.04137687, 0.15984032, 0.08002143]]],\n",
       "      dtype=float32)>"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_layer(batch)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "417d98d3-d462-4a95-90bf-021630ff90d2",
   "metadata": {},
   "source": [
    "# Vocabulary Initialization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "0b493589-2ddc-4b8f-9c28-e1a25894415a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['#define', '#include', '#if', '#else', '#endif', 'auto', 'break', 'case', 'char', 'const', 'continue', 'default', 'do', 'double', 'else', 'enum', 'extern', 'float', 'for', 'goto', 'if', 'int', 'long', 'register', 'return', 'short', 'signed', 'sizeof', 'static', 'struct', 'switch', 'typedef', 'union', 'unsigned', 'void', 'volatile', 'while', '_Bool', '_Complex', '_Imaginary', 'inline', 'restrict', '_Alignas', '_Alignof', '_Atomic', '_Generic', '_Noreturn', '_Static_assert', '_Thread_local', '+', '-', '*', '/', '%', '==', '!=', '>', '<', '>=', '<=', '&&', '||', '!', '&', '|', '^', '~', '<<', '>>', '++', '--', '*', '&', 'sizeof', '?:', ',', '.', '->', '%int', '%var', '%float', '%string', '%func', '%class', ';', '{', '}', '{}', '']\n"
     ]
    }
   ],
   "source": [
    "with open(\"/Users/joericks/Desktop/nova/model/constants/vocabulary.txt\", \"r\") as f:\n",
    "    vocab = f.read().split('\\n')\n",
    "    print(vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "f473304b-c3e2-4385-beb8-ffb93a889de8",
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab_size = len(vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "d1b563c0-f28d-4926-8db5-159ce9b6ecfd",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_final_layer = TransformerFinalLayer(vocab_size, batch.shape[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "1868aa08-2db1-48e2-bf39-4b7315c7b7f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def mean(arr):\n",
    "    return sum([i*arr[i] for i in range(0, len(arr))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "2bf14b32-99aa-4db1-84c2-252b912be792",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(1, 5, 89), dtype=float32, numpy=\n",
       "array([[[0.00978142, 0.0065435 , 0.00821909, 0.00429984, 0.02690102,\n",
       "         0.0061669 , 0.01417588, 0.0050653 , 0.00396573, 0.02046988,\n",
       "         0.00776417, 0.01684113, 0.01805889, 0.005921  , 0.0077371 ,\n",
       "         0.01003014, 0.0110882 , 0.01500982, 0.00334477, 0.00905581,\n",
       "         0.02510174, 0.00771801, 0.00572649, 0.00161598, 0.02371358,\n",
       "         0.02326424, 0.00909672, 0.01462158, 0.02120908, 0.013144  ,\n",
       "         0.00205382, 0.00978873, 0.00560785, 0.00257272, 0.01867482,\n",
       "         0.00901906, 0.00361429, 0.00991141, 0.00912776, 0.02127976,\n",
       "         0.01272175, 0.00336248, 0.01069815, 0.00403742, 0.00513064,\n",
       "         0.01039648, 0.00496457, 0.00771462, 0.04948825, 0.0235945 ,\n",
       "         0.0255486 , 0.00627909, 0.00449078, 0.00976756, 0.01833355,\n",
       "         0.02072923, 0.0026971 , 0.01644593, 0.0054278 , 0.01181918,\n",
       "         0.01125352, 0.00982694, 0.00453483, 0.01572102, 0.00467145,\n",
       "         0.03364301, 0.01184075, 0.002803  , 0.00603518, 0.00766507,\n",
       "         0.01859192, 0.01770097, 0.01142324, 0.00860267, 0.0040363 ,\n",
       "         0.0180678 , 0.01252695, 0.02820319, 0.00973739, 0.00350373,\n",
       "         0.01193521, 0.00534077, 0.00845153, 0.00791841, 0.00297045,\n",
       "         0.00866831, 0.00990889, 0.00266959, 0.00079899],\n",
       "        [0.0089195 , 0.00291768, 0.00197608, 0.00375676, 0.0526684 ,\n",
       "         0.00661399, 0.0084031 , 0.01808861, 0.00622857, 0.01074464,\n",
       "         0.00652618, 0.00347647, 0.01593376, 0.0045918 , 0.00331811,\n",
       "         0.02055263, 0.00310142, 0.0063939 , 0.00465727, 0.03045793,\n",
       "         0.10630366, 0.01167598, 0.01595905, 0.00210778, 0.01257786,\n",
       "         0.02418911, 0.00187   , 0.00924716, 0.00398533, 0.00511341,\n",
       "         0.00735548, 0.00623689, 0.01565401, 0.00562482, 0.00859009,\n",
       "         0.00318648, 0.00750022, 0.03973803, 0.00308572, 0.00838552,\n",
       "         0.0197954 , 0.00128826, 0.01430813, 0.00400398, 0.00210094,\n",
       "         0.01281566, 0.00861096, 0.00647143, 0.01664106, 0.02584504,\n",
       "         0.01211416, 0.01019184, 0.00284042, 0.0176857 , 0.00352764,\n",
       "         0.01106727, 0.00187889, 0.01311221, 0.01784153, 0.00715091,\n",
       "         0.0060976 , 0.00732859, 0.0028885 , 0.00771354, 0.01006708,\n",
       "         0.01365614, 0.00710177, 0.00189922, 0.01058995, 0.00872918,\n",
       "         0.00667689, 0.00705691, 0.01789897, 0.02280596, 0.01000787,\n",
       "         0.00877625, 0.0142178 , 0.00197332, 0.00952133, 0.00797087,\n",
       "         0.00844435, 0.00500334, 0.00433846, 0.00281798, 0.00546952,\n",
       "         0.00686038, 0.05025953, 0.00543783, 0.0013859 ],\n",
       "        [0.00566251, 0.0064478 , 0.00720257, 0.00217068, 0.01012135,\n",
       "         0.00918857, 0.0062179 , 0.0113141 , 0.00339536, 0.01281125,\n",
       "         0.01894725, 0.02371668, 0.01349743, 0.00616697, 0.00427389,\n",
       "         0.01738716, 0.00729261, 0.01897745, 0.00263204, 0.01129166,\n",
       "         0.03777796, 0.02071382, 0.00909287, 0.00659255, 0.01400808,\n",
       "         0.01253166, 0.00998901, 0.00793151, 0.01225606, 0.01442548,\n",
       "         0.01550715, 0.00637817, 0.0087298 , 0.00863102, 0.01021768,\n",
       "         0.00877832, 0.00689509, 0.01958329, 0.00986708, 0.00427603,\n",
       "         0.01384442, 0.00588186, 0.02572924, 0.00338422, 0.01637849,\n",
       "         0.01926357, 0.00271363, 0.00918478, 0.02810847, 0.0087168 ,\n",
       "         0.0144038 , 0.00706876, 0.00719419, 0.01811156, 0.00342481,\n",
       "         0.01327504, 0.00451002, 0.02299302, 0.01177334, 0.01031468,\n",
       "         0.02693165, 0.00982533, 0.00946307, 0.01340658, 0.01330821,\n",
       "         0.01215486, 0.01046618, 0.00330276, 0.00696624, 0.00208227,\n",
       "         0.02100068, 0.01059112, 0.01453277, 0.00899941, 0.00391826,\n",
       "         0.01419079, 0.00902876, 0.00932058, 0.00392318, 0.00435428,\n",
       "         0.01357732, 0.01198168, 0.00823474, 0.00610435, 0.01355468,\n",
       "         0.00914407, 0.01792531, 0.01464094, 0.00789741],\n",
       "        [0.00527002, 0.00341376, 0.01620599, 0.00822357, 0.0260387 ,\n",
       "         0.00247668, 0.00853676, 0.01282058, 0.00518285, 0.01145333,\n",
       "         0.00568269, 0.00593793, 0.04685549, 0.0142633 , 0.01032411,\n",
       "         0.01397366, 0.00455658, 0.00863993, 0.00394821, 0.01538106,\n",
       "         0.02020065, 0.00460945, 0.00727131, 0.0057826 , 0.03241219,\n",
       "         0.01300288, 0.00968439, 0.01118919, 0.01425035, 0.0117208 ,\n",
       "         0.00808041, 0.0090805 , 0.00584973, 0.00553038, 0.00740574,\n",
       "         0.00395234, 0.0051295 , 0.00490877, 0.00979687, 0.00846761,\n",
       "         0.00910871, 0.00208616, 0.03037004, 0.00526731, 0.00628849,\n",
       "         0.01970512, 0.01753731, 0.0042485 , 0.02214178, 0.00831092,\n",
       "         0.03465031, 0.00985255, 0.00638721, 0.0079651 , 0.0054675 ,\n",
       "         0.03645224, 0.00537321, 0.01343974, 0.00764807, 0.01035204,\n",
       "         0.01532724, 0.00852944, 0.0033478 , 0.02529385, 0.00433664,\n",
       "         0.0119968 , 0.00921013, 0.00342472, 0.00919851, 0.01099278,\n",
       "         0.011414  , 0.01301152, 0.00515533, 0.00739001, 0.00388318,\n",
       "         0.01724238, 0.01980748, 0.00664815, 0.00686481, 0.0074278 ,\n",
       "         0.02459937, 0.00918543, 0.0115309 , 0.0135403 , 0.00571464,\n",
       "         0.0075405 , 0.02693169, 0.00909619, 0.00119533],\n",
       "        [0.00428938, 0.00271343, 0.00893528, 0.00373298, 0.02869125,\n",
       "         0.00299931, 0.01057425, 0.00401134, 0.00347408, 0.0104233 ,\n",
       "         0.01492962, 0.00524359, 0.0138771 , 0.014886  , 0.00654703,\n",
       "         0.02862099, 0.00414004, 0.0061314 , 0.00684001, 0.01053164,\n",
       "         0.05334251, 0.02028715, 0.00557627, 0.00440692, 0.02409459,\n",
       "         0.01049122, 0.01246276, 0.00478509, 0.01579674, 0.02050951,\n",
       "         0.00584825, 0.02416384, 0.0043539 , 0.00470313, 0.00439241,\n",
       "         0.00778365, 0.00543032, 0.02199988, 0.00706988, 0.01720786,\n",
       "         0.01258481, 0.00656091, 0.01652273, 0.00224673, 0.00479992,\n",
       "         0.05417943, 0.01448034, 0.00311533, 0.01793399, 0.01069033,\n",
       "         0.0254109 , 0.01428351, 0.00659884, 0.0076198 , 0.00482879,\n",
       "         0.00519216, 0.0039369 , 0.01173312, 0.0034095 , 0.00899509,\n",
       "         0.02041767, 0.00490001, 0.00835908, 0.01174582, 0.00775466,\n",
       "         0.00350545, 0.00978504, 0.00835785, 0.00641095, 0.00608458,\n",
       "         0.00551067, 0.00746386, 0.00807753, 0.00924836, 0.0070345 ,\n",
       "         0.0276114 , 0.00729764, 0.00848572, 0.00302511, 0.01408677,\n",
       "         0.01263486, 0.00291006, 0.00935456, 0.01224454, 0.01544693,\n",
       "         0.01259231, 0.03883083, 0.00627376, 0.0031284 ]]], dtype=float32)>"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final = new_final_layer(batch)\n",
    "final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "fbd946cb-854a-4297-b522-da923811a454",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(43.136044, shape=(), dtype=float32)\n",
      "tf.Tensor(40.895535, shape=(), dtype=float32)\n",
      "tf.Tensor(43.852276, shape=(), dtype=float32)\n",
      "tf.Tensor(43.80238, shape=(), dtype=float32)\n",
      "tf.Tensor(43.360542, shape=(), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "means = []\n",
    "\n",
    "for i in range(final.shape[0]):\n",
    "    for j in range(final.shape[1]):\n",
    "        print(mean(final[i,j]))\n",
    "        means.append(mean(final[i,j]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "929d1d75-aeb4-45ed-a670-3f854baba839",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<tf.Tensor: shape=(), dtype=float32, numpy=45.7917>,\n",
       " <tf.Tensor: shape=(), dtype=float32, numpy=43.750305>,\n",
       " <tf.Tensor: shape=(), dtype=float32, numpy=46.327908>,\n",
       " <tf.Tensor: shape=(), dtype=float32, numpy=46.486794>,\n",
       " <tf.Tensor: shape=(), dtype=float32, numpy=45.664543>]"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "means"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "6343a1e4-d3c3-41ff-ab91-7fca2eb975df",
   "metadata": {},
   "outputs": [],
   "source": [
    "import datasets\n",
    "import ast\n",
    "from nova_py import TACO\n",
    "import tensorflow as tf\n",
    "import re\n",
    "import pickle\n",
    "import string\n",
    "import itertools"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5732f13b-5a07-4c77-bdb0-b61e9578488a",
   "metadata": {},
   "source": [
    "# Overall Vocabulary build"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f4f64783-c412-4f90-9837-ba3fde7649ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Vocabulary:\n",
    "    def __init__(self):\n",
    "        self.taco = {\n",
    "            \"patterns\": {\n",
    "                \"quote_search\": r'\"[^\"]*\"|[^\"\\s]+',\n",
    "                \"word_match\": r'\\w+|[^\\w\\s]',\n",
    "                \"quote_split\": r'\\\"+|.+(?<!\\\")'\n",
    "            },\n",
    "            \"splits\": [\"\\\"\", \"'\"],\n",
    "            \"tokens\": {}\n",
    "        }\n",
    "        self.performer = {\n",
    "            \"in_tokens\": {},\n",
    "            \"out_tokens\": {}\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "10eef43b-4e2f-48c1-a067-51fa32956f89",
   "metadata": {},
   "outputs": [],
   "source": [
    "v = Vocabulary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f8b9385-eaac-4000-88ff-a46ecd6d3274",
   "metadata": {},
   "source": [
    "# Main (Output vocabulary for performer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a0ee37c4-a38b-4187-8f60-0e4daa4b0e15",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "229e4ab72cb84336a1aa508a0ebdc30c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Resolving data files:   0%|          | 0/54 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "dataset_name = \"codeparrot/codeparrot-clean\"\n",
    "\n",
    "vocab_set = datasets.load_dataset(dataset_name, 'default', split='train', streaming=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "0df1bbf6-1f91-44b0-804c-0e40ada8fdb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab_text = [i['content'] for i in vocab_set.take(300)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "db16b77c-2790-4202-8cb7-9bf5d3584030",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Escaped\n",
      "Escaped\n",
      "Escaped\n",
      "Escaped\n",
      "Escaped\n",
      "Escaped\n",
      "Escaped\n",
      "Escaped\n",
      "Escaped\n",
      "Escaped\n",
      "Escaped\n",
      "Escaped\n",
      "Escaped\n",
      "Escaped\n",
      "Escaped\n",
      "Escaped\n",
      "Escaped\n",
      "Escaped\n",
      "Escaped\n",
      "Escaped\n",
      "Escaped\n",
      "Escaped\n",
      "Escaped\n",
      "Escaped\n",
      "Escaped\n",
      "Escaped\n",
      "Escaped\n",
      "Escaped\n",
      "Escaped\n",
      "Escaped\n",
      "Escaped\n",
      "Escaped\n",
      "Escaped\n",
      "Escaped\n",
      "Escaped\n",
      "Escaped\n",
      "Escaped\n",
      "Escaped\n",
      "Escaped\n",
      "Escaped\n",
      "Escaped\n",
      "Escaped\n",
      "Escaped\n",
      "Escaped\n",
      "Escaped\n",
      "Escaped\n",
      "Escaped\n",
      "Escaped\n",
      "Escaped\n"
     ]
    }
   ],
   "source": [
    "trees = []\n",
    "for script in vocab_text:\n",
    "    try:\n",
    "        trees.append(ast.dump(ast.parse(script)))\n",
    "    except:\n",
    "        print(\"Escaped\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "0b51e65f-e8d3-4990-bc4f-ee27ed72e2bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "splits = []\n",
    "for tree in trees:\n",
    "    split = re.findall(r\"(?sx)(?:\\\"\\\"\\\"(?:\\\\.|(?!\\\"\\\"\\\").)*?\\\"\\\"\\\"|'''(?:\\\\.|(?!''').)*?'''|\\\"(?:(?:[^\\\"\\\\]|\\\\.)*)\\\"|'(?:(?:[^'\\\\]|\\\\.)*)'|[^\\\"'\\d]+)\", tree)\n",
    "    splits.append(split)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "09e69f25-b956-4c1b-b9e8-9852d5b88b8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokens = []\n",
    "for split in splits:\n",
    "    for string in split:\n",
    "        num_quotes = len(re.findall(r\"[\\\"\\']\", string))\n",
    "        if not num_quotes > 1:\n",
    "            tokens.append(string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "d623382d-35d2-40c6-9f6e-0ee32be29d70",
   "metadata": {},
   "outputs": [],
   "source": [
    "cleaning_pattern = r'\\w+|\\W'\n",
    "\n",
    "clean_tokens = []\n",
    "for t in tokens:\n",
    "    for t2 in re.findall(cleaning_pattern, t):\n",
    "        clean_tokens.append(t2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "f628bde4-7b53-4c16-b1e8-5d8dddf0b90a",
   "metadata": {},
   "outputs": [],
   "source": [
    "vocabulary, _ = tf.unique(tf.constant(clean_tokens))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "31dc3ee7-b9bc-462c-b292-ee3639c850e9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(157,), dtype=string, numpy=\n",
       "array([b'Module', b'(', b'body', b'=', b'[', b'ImportFrom', b'module',\n",
       "       b',', b' ', b'names', b'alias', b'name', b')', b']', b'level',\n",
       "       b'Import', b'ClassDef', b'bases', b'Name', b'id', b'ctx', b'Load',\n",
       "       b'keywords', b'FunctionDef', b'args', b'arguments', b'posonlyargs',\n",
       "       b'arg', b'kwonlyargs', b'kw_defaults', b'defaults', b'Expr',\n",
       "       b'value', b'Call', b'func', b'Attribute', b'Constant', b'attr',\n",
       "       b'decorator_list', b'While', b'test', b'True', b'kind', b'b',\n",
       "       b'keyword', b'YieldFrom', b'orelse', b'If', b'Compare', b'left',\n",
       "       b'ops', b'Eq', b'comparators', b'Assign', b'targets', b'Store',\n",
       "       b'False', b'type_ignores', b'vararg', b'kwarg', b'None', b'IfExp',\n",
       "       b'Subscript', b'slice', b'Return', b'AugAssign', b'target', b'op',\n",
       "       b'Add', b'Tuple', b'elts', b'List', b'IsNot', b'ListComp', b'elt',\n",
       "       b'generators', b'comprehension', b'iter', b'ifs', b'UnaryOp',\n",
       "       b'Not', b'operand', b'is_async', b'NotIn', b'For', b'Assert',\n",
       "       b'msg', b'BinOp', b'Mod', b'right', b'In', b'GeneratorExp',\n",
       "       b'asname', b'Starred', b'Raise', b'exc', b'Is', b'Gt', b'Slice',\n",
       "       b'upper', b'Pow', b'FloorDiv', b'Lt', b'Yield', b'Pass', b'Dict',\n",
       "       b'keys', b'values', b'BoolOp', b'And', b'Continue', b'Try',\n",
       "       b'handlers', b'ExceptHandler', b'type', b'finalbody', b'Or',\n",
       "       b'Sub', b'LtE', b'lower', b'GtE', b'With', b'items', b'withitem',\n",
       "       b'context_expr', b'Break', b'NotEq', b'optional_vars', b'USub',\n",
       "       b'LShift', b'Mult', b'.', b'Div', b'Lambda', b'Delete', b'Del',\n",
       "       b'DictComp', b'key', b'step', b'JoinedStr', b'FormattedValue',\n",
       "       b'conversion', b'-', b'AsyncFunctionDef', b'format_spec',\n",
       "       b'Global', b'e', b'Set', b'Await', b'annotation', b'returns',\n",
       "       b'RShift', b'BitOr', b'cause', b'BitAnd', b'+', b'SetComp'],\n",
       "      dtype=object)>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocabulary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "c9fd8b0e-d868-4038-894c-6990c7271846",
   "metadata": {},
   "outputs": [],
   "source": [
    "flat_tokens, _ = tf.unique(tf.reshape(tokens, [-1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "68953911-9666-42d8-9734-2ff14313f823",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(7104,), dtype=string, numpy=\n",
       "array([b'Module(body=[ImportFrom(module=', b', names=[alias(name=',\n",
       "       b'), alias(name=', ...,\n",
       "       b', ctx=Load()), args=[ListComp(elt=Tuple(elts=[Name(id=',\n",
       "       b', ctx=Load()), ctx=Load())], ctx=Load()), generators=[comprehension(target=Name(id=',\n",
       "       b', ctx=Load())], keywords=[])), body=[Return(value=Constant(value=False))], orelse=[]), Return(value=Compare(left=Call(func=Attribute(value=Name(id='],\n",
       "      dtype=object)>"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "flat_tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "9af4e10f-4bfd-4e91-9338-186d6783db4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "text_dump = [w.decode('utf-8') for w in vocabulary.numpy()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "b080c09c-7c5f-4c8d-8fe9-aabb7b07f193",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "157"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(text_dump)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "d3e2a3d4-b9b3-4167-88d3-47569b00c565",
   "metadata": {},
   "outputs": [],
   "source": [
    "v.performer['out_tokens'] = {i+1: text_dump[i] for i in range(0, len(text_dump))}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "a5a13b2a-dc8a-4cd5-82de-ce182a03b08d",
   "metadata": {},
   "outputs": [],
   "source": [
    "special_tokens = [\"#MEM\", \"\\'\", \"\\\"\", \"#PAD\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "75aa8f5c-249d-49b3-8824-e0ec6490a8b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "v.performer['out_tokens'] = {**v.performer['out_tokens'],\n",
    "                             **{i+len(v.performer['out_tokens'].values())+1: special_tokens[i] for i in range(0, len(special_tokens))}}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "f0c95e5e-0c07-4e83-9a3a-bbda55c90872",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'in_tokens': {},\n",
       " 'out_tokens': {1: 'Module',\n",
       "  2: '(',\n",
       "  3: 'body',\n",
       "  4: '=',\n",
       "  5: '[',\n",
       "  6: 'ImportFrom',\n",
       "  7: 'module',\n",
       "  8: ',',\n",
       "  9: ' ',\n",
       "  10: 'names',\n",
       "  11: 'alias',\n",
       "  12: 'name',\n",
       "  13: ')',\n",
       "  14: ']',\n",
       "  15: 'level',\n",
       "  16: 'Import',\n",
       "  17: 'ClassDef',\n",
       "  18: 'bases',\n",
       "  19: 'Name',\n",
       "  20: 'id',\n",
       "  21: 'ctx',\n",
       "  22: 'Load',\n",
       "  23: 'keywords',\n",
       "  24: 'FunctionDef',\n",
       "  25: 'args',\n",
       "  26: 'arguments',\n",
       "  27: 'posonlyargs',\n",
       "  28: 'arg',\n",
       "  29: 'kwonlyargs',\n",
       "  30: 'kw_defaults',\n",
       "  31: 'defaults',\n",
       "  32: 'Expr',\n",
       "  33: 'value',\n",
       "  34: 'Call',\n",
       "  35: 'func',\n",
       "  36: 'Attribute',\n",
       "  37: 'Constant',\n",
       "  38: 'attr',\n",
       "  39: 'decorator_list',\n",
       "  40: 'While',\n",
       "  41: 'test',\n",
       "  42: 'True',\n",
       "  43: 'kind',\n",
       "  44: 'b',\n",
       "  45: 'keyword',\n",
       "  46: 'YieldFrom',\n",
       "  47: 'orelse',\n",
       "  48: 'If',\n",
       "  49: 'Compare',\n",
       "  50: 'left',\n",
       "  51: 'ops',\n",
       "  52: 'Eq',\n",
       "  53: 'comparators',\n",
       "  54: 'Assign',\n",
       "  55: 'targets',\n",
       "  56: 'Store',\n",
       "  57: 'False',\n",
       "  58: 'type_ignores',\n",
       "  59: 'vararg',\n",
       "  60: 'kwarg',\n",
       "  61: 'None',\n",
       "  62: 'IfExp',\n",
       "  63: 'Subscript',\n",
       "  64: 'slice',\n",
       "  65: 'Return',\n",
       "  66: 'AugAssign',\n",
       "  67: 'target',\n",
       "  68: 'op',\n",
       "  69: 'Add',\n",
       "  70: 'Tuple',\n",
       "  71: 'elts',\n",
       "  72: 'List',\n",
       "  73: 'IsNot',\n",
       "  74: 'ListComp',\n",
       "  75: 'elt',\n",
       "  76: 'generators',\n",
       "  77: 'comprehension',\n",
       "  78: 'iter',\n",
       "  79: 'ifs',\n",
       "  80: 'UnaryOp',\n",
       "  81: 'Not',\n",
       "  82: 'operand',\n",
       "  83: 'is_async',\n",
       "  84: 'NotIn',\n",
       "  85: 'For',\n",
       "  86: 'Assert',\n",
       "  87: 'msg',\n",
       "  88: 'BinOp',\n",
       "  89: 'Mod',\n",
       "  90: 'right',\n",
       "  91: 'In',\n",
       "  92: 'GeneratorExp',\n",
       "  93: 'asname',\n",
       "  94: 'Starred',\n",
       "  95: 'Raise',\n",
       "  96: 'exc',\n",
       "  97: 'Is',\n",
       "  98: 'Gt',\n",
       "  99: 'Slice',\n",
       "  100: 'upper',\n",
       "  101: 'Pow',\n",
       "  102: 'FloorDiv',\n",
       "  103: 'Lt',\n",
       "  104: 'Yield',\n",
       "  105: 'Pass',\n",
       "  106: 'Dict',\n",
       "  107: 'keys',\n",
       "  108: 'values',\n",
       "  109: 'BoolOp',\n",
       "  110: 'And',\n",
       "  111: 'Continue',\n",
       "  112: 'Try',\n",
       "  113: 'handlers',\n",
       "  114: 'ExceptHandler',\n",
       "  115: 'type',\n",
       "  116: 'finalbody',\n",
       "  117: 'Or',\n",
       "  118: 'Sub',\n",
       "  119: 'LtE',\n",
       "  120: 'lower',\n",
       "  121: 'GtE',\n",
       "  122: 'With',\n",
       "  123: 'items',\n",
       "  124: 'withitem',\n",
       "  125: 'context_expr',\n",
       "  126: 'Break',\n",
       "  127: 'NotEq',\n",
       "  128: 'optional_vars',\n",
       "  129: 'USub',\n",
       "  130: 'LShift',\n",
       "  131: 'Mult',\n",
       "  132: '.',\n",
       "  133: 'Div',\n",
       "  134: 'Lambda',\n",
       "  135: 'Delete',\n",
       "  136: 'Del',\n",
       "  137: 'DictComp',\n",
       "  138: 'key',\n",
       "  139: 'step',\n",
       "  140: 'JoinedStr',\n",
       "  141: 'FormattedValue',\n",
       "  142: 'conversion',\n",
       "  143: '-',\n",
       "  144: 'AsyncFunctionDef',\n",
       "  145: 'format_spec',\n",
       "  146: 'Global',\n",
       "  147: 'e',\n",
       "  148: 'Set',\n",
       "  149: 'Await',\n",
       "  150: 'annotation',\n",
       "  151: 'returns',\n",
       "  152: 'RShift',\n",
       "  153: 'BitOr',\n",
       "  154: 'cause',\n",
       "  155: 'BitAnd',\n",
       "  156: '+',\n",
       "  157: 'SetComp',\n",
       "  158: '#MEM',\n",
       "  159: \"'\",\n",
       "  160: '\"',\n",
       "  161: '#PAD'}}"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "v.performer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "95fa7310-651e-4a3d-b38e-4f967c9dda51",
   "metadata": {},
   "outputs": [],
   "source": [
    "chars = list(string.printable)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "d03e76c0-aa99-4c56-8aec-68aba63cf306",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer_vocab = chars + list(itertools.product(chars, repeat=2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "e0f04dac-cde2-42b7-9d90-0ed7d58049ee",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'patterns': {'quote_search': '\"[^\"]*\"|[^\"\\\\s]+',\n",
       "  'word_match': '\\\\w+|[^\\\\w\\\\s]',\n",
       "  'quote_split': '\\\\\"+|.+(?<!\\\\\")'},\n",
       " 'splits': ['\"', \"'\"],\n",
       " 'tokens': {}}"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "v.taco['tokens'] = {i+1: tokenizer_vocab[i] for "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72e4e667-fc52-4d2e-ab49-0e52f285ae5e",
   "metadata": {},
   "source": [
    "# Save Vocabulary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "67361aa0-0de5-423e-b4d1-60918d4ae92a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save to a pickle file\n",
    "with open(\"/Users/joericks/Desktop/nova/nova-py/src/nova_py/model/vocab.pkl\", \"wb\") as f:\n",
    "    pickle.dump(v, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a02ff84-5a74-4601-b756-a05defbf41a2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "b520ebd1-d2db-4523-81ff-6952f0221be0",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# Regex Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "id": "f2ae14b6-3967-4ba9-a827-b474b5cb6c01",
   "metadata": {},
   "outputs": [],
   "source": [
    "def word_split(string):\n",
    "    if string == \"\":\n",
    "        return\n",
    "    quote_match = r'\"[^\"]*\"|[^\"\\s]+'\n",
    "    splits = re.findall(quote_match, string)\n",
    "    custom_match = r'\\w+|[^\\w\\s]'\n",
    "    quote_split = r'\\\"+|.+(?<!\\\")'\n",
    "    tokens = []\n",
    "    for i in splits:\n",
    "        if \"\\\"\" in i:\n",
    "            arr = re.findall(quote_split, i)\n",
    "            tokens += arr\n",
    "        else:\n",
    "            arr = re.findall(custom_match, i)\n",
    "            tokens += arr\n",
    "    return tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "id": "0009d138-4b17-4f3f-8f4a-82d46fd907fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "test = \"hello =\\\"good world!\\\" goodbye = 0\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "id": "f8c3fcd9-5806-4bba-9490-a4ec05c6baa6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['hello', '=', '\"', 'good world!', '\"', 'goodbye', '=', '0']"
      ]
     },
     "execution_count": 243,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_split(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04325a7e-cd93-4d11-93b2-8e73b593736c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

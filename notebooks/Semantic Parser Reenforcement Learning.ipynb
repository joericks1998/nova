{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c110cc05-5d0a-4a4c-90d2-a66684fa3d86",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['/Users/joericks/Desktop/nova',\n",
       " '/usr/local/Cellar/python@3.9/3.9.13_1/Frameworks/Python.framework/Versions/3.9/lib/python39.zip',\n",
       " '/usr/local/Cellar/python@3.9/3.9.13_1/Frameworks/Python.framework/Versions/3.9/lib/python3.9',\n",
       " '/usr/local/Cellar/python@3.9/3.9.13_1/Frameworks/Python.framework/Versions/3.9/lib/python3.9/lib-dynload',\n",
       " '',\n",
       " '/usr/local/lib/python3.9/site-packages']"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from semantics import parser, tokenizer\n",
    "from inference import main\n",
    "import numpy as np\n",
    "from Levenshtein import distance\n",
    "import importlib\n",
    "import sys\n",
    "import json\n",
    "\n",
    "sys.path"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2452140f-b49e-4616-9302-b294dbbf2932",
   "metadata": {},
   "source": [
    "The goal of this is to come up with a reasonable reenforcement learning algorithm for the encoding model first, so that when training nova begins, most of the encoding can be handled in an automated way"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e24182ab-d48d-45a2-8cf8-354557eb6be2",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Whiteboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "05658d40-050c-4cbc-b514-457dde619277",
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder = parser.Encoder.load(\"model/semantics\")\n",
    "\n",
    "def getSimWeights(sequence):\n",
    "    return tf.constant([1-distance(sequence.replace(' -> ', ''), k.replace(' -> ', ''))/max(len(k), len(sequence)) for k, v in encoder.TransitionStates.items()])\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5155ebef-28fe-48fc-82bf-b7d95e74dc23",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(4,), dtype=float32, numpy=array([0.2857143 , 0.64285713, 0.5714286 , 0.5263158 ], dtype=float32)>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "v = getSimWeights('~pad~ -> ~pad~')\n",
    "v"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "282558fb-c1a7-411b-ad7f-8bbf5a408159",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'': 1,\n",
       " '~pad~': 2,\n",
       " '~pad~ -> ~var~ -> ~relation~': 3,\n",
       " '~var~ -> ~relation~': 4}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoder.TransitionStates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "044b851c-3dcc-479b-bc9c-3c4f87519fb7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(4, 10), dtype=float32, numpy=\n",
       "array([[0.        , 0.        , 0.2857143 , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.64285713, 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.5714286 , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.5263158 , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ]],\n",
       "      dtype=float32)>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p_mtrx = encoder.TransitionMatrix[1:,:] * v[:, tf.newaxis]\n",
    "p_mtrx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ca3ad17c-15b6-4773-922e-979c5e9f634d",
   "metadata": {},
   "outputs": [],
   "source": [
    "logits = tf.Variable([sum(p_mtrx[:,i]) for i in range(0, p_mtrx.shape[1])])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "id": "152c8034-c062-4679-8968-ddf1a63f07c0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(10,), dtype=float32, numpy=\n",
       "array([0.07391918, 0.07391918, 0.18708138, 0.22156517, 0.07391918,\n",
       "       0.07391918, 0.07391918, 0.07391918, 0.07391918, 0.07391918],\n",
       "      dtype=float32)>"
      ]
     },
     "execution_count": 191,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "probabilities = tf.nn.softmax(logits,axis=-1)\n",
    "probabilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "id": "aa0f3936-501c-4bb7-9f6a-b1470e61f374",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tf_mode(tensor):\n",
    "    \"\"\"Computes the mode of a 1D tensor.\"\"\"\n",
    "    tensor_1d = tf.reshape(tensor, [-1])\n",
    "    values, _, counts = tf.unique_with_counts(tensor_1d)\n",
    "    max_index = tf.argmax(counts)\n",
    "    return tf.gather(values, max_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "id": "7098a0a4-23f5-470f-8f45-e3e0f7cacd18",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize variables\n",
    "wrong_answers = [0, 1, 2, 3, 5, 6, 7, 8, 9]\n",
    "num_epochs = 10\n",
    "num_bad = tf.Variable(0, dtype=tf.int32)  # Track the number of bad updates\n",
    "# probabilities = tf.Variable(tf.random.uniform([10], dtype=tf.float32))  # Example initialization of probabilities\n",
    "\n",
    "# Normalize the probabilities initially\n",
    "probabilities.assign(probabilities / tf.reduce_sum(probabilities))\n",
    "\n",
    "# Training loop\n",
    "for epoch in range(num_epochs):\n",
    "    # Sample actions according to the current probabilities distribution\n",
    "    samples = tf.random.categorical(tf.math.log([probabilities]), num_samples=5)\n",
    "    \n",
    "    # Get the mode of the sampled actions (this will be the most frequent action)\n",
    "    mode = tf_mode(samples)\n",
    "    \n",
    "    # Check if the mode is in wrong answers\n",
    "    is_wrong = tf.reduce_any(tf.equal(mode, wrong_answers))\n",
    "\n",
    "    if is_wrong:\n",
    "        num_bad.assign_add(1)  # Increment the number of bad updates\n",
    "        # Update probabilities by averaging the wrong answer's probability with 0\n",
    "        probabilities = tf.tensor_scatter_nd_update(probabilities, [[mode]], [tf.reduce_mean([probabilities[mode], 0])])\n",
    "        probabilities /= tf.reduce_sum(probabilities)  # Normalize after update\n",
    "    else:\n",
    "        # Reduce the wrong answers' probabilities to 0 (like penalizing)\n",
    "        wrong_probs = tf.gather(probabilities, wrong_answers)\n",
    "        zero_tensor = tf.zeros_like(wrong_probs)  # Create a tensor of zeros with the same shape as wrong_probs\n",
    "        vals = tf.reduce_mean([wrong_probs, zero_tensor], axis=0)\n",
    "        idxs = tf.constant(wrong_answers, dtype=tf.int32)\n",
    "        probabilities = tf.tensor_scatter_nd_update(probabilities, tf.reshape(idxs, (-1, 1)), vals)\n",
    "        probabilities /= tf.reduce_sum(probabilities)   # Normalize after update\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 290,
   "id": "724226a5-4ee3-44ef-9f74-cd5b7d0c8197",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(10,), dtype=float32, numpy=\n",
       "array([0.07391918, 0.07391918, 0.18708138, 0.22156517, 0.07391918,\n",
       "       0.07391918, 0.07391918, 0.07391918, 0.07391918, 0.07391918],\n",
       "      dtype=float32)>"
      ]
     },
     "execution_count": 290,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "probabilities = tf.nn.softmax(logits,axis=-1)\n",
    "probabilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 301,
   "id": "26ea09d0-82ae-4e44-8a1f-8360786202fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def reenforce(probabilities, mode, num_epochs = 1, is_bad = False, num_bad = 0):\n",
    "    for epoch in range(num_epochs):\n",
    "        if is_bad:\n",
    "            # num_bad.assign_add(1)  # Increment the number of bad updates\n",
    "            # Update probabilities by averaging the wrong answer's probability with 0\n",
    "            probabilities = tf.tensor_scatter_nd_update(probabilities, [[mode]], [tf.reduce_mean([probabilities[mode], 0])])\n",
    "            probabilities /= tf.reduce_sum(probabilities)  # Normalize after update\n",
    "        else:\n",
    "            # Reduce the wrong answers' probabilities to 0 (like penalizing)\n",
    "            one_hot_tensor = tf.one_hot(mode, probabilities.shape[0])  # Create a tensor of zeros with the same shape as wrong_probs\n",
    "            probabilities = tf.reduce_mean([probabilities, one_hot_tensor], axis=0)\n",
    "   # Normalize after update\n",
    "    return probabilities\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 315,
   "id": "9ef63499-8d8e-48d8-b4e9-3f8bddbac56a",
   "metadata": {},
   "outputs": [],
   "source": [
    "probabilities = reenforce(probabilities, 7, num_epochs = 10, is_bad = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 316,
   "id": "1a0d9c70-8272-46be-bc9c-d36e2c01f58b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(10,), dtype=float32, numpy=\n",
       "array([8.6735785e-02, 8.6735785e-02, 2.1951883e-01, 2.5998166e-01,\n",
       "       8.6735785e-02, 8.6735785e-02, 8.6735785e-02, 8.4702915e-05,\n",
       "       8.2717690e-08, 8.6735785e-02], dtype=float32)>"
      ]
     },
     "execution_count": 316,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "probabilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 293,
   "id": "a1c2ef20-1ade-49d6-964d-d2ff67b6d6c0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.07391918, 0.07391918, 0.18708138, 0.22156517, 0.07391918,\n",
       "       0.07391918, 0.07391918, 0.07391918, 0.07391918, 0.07391918],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 293,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "probabilities.numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 283,
   "id": "44a4647a-8af1-4618-abf2-f8f96e1857fa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(), dtype=float32, numpy=1.0000001>"
      ]
     },
     "execution_count": 283,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(probabilities)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 282,
   "id": "1e9918e2-f9da-44df-9015-47308f0185ca",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(), dtype=float64, numpy=0.01>"
      ]
     },
     "execution_count": 282,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_bad/num_epocs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "id": "3801797d-bee2-4447-9cd8-ddf15f928461",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(10,), dtype=float32, numpy=\n",
       "array([0.13505921, 0.08938976, 0.10936902, 0.06480423, 0.20316379,\n",
       "       0.04681202, 0.03829137, 0.05723381, 0.13689348, 0.11898329],\n",
       "      dtype=float32)>"
      ]
     },
     "execution_count": 194,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "probabilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 257,
   "id": "d0e42fac-2877-4156-b270-5d34f8a03246",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(4,), dtype=float32, numpy=array([0., 0., 0., 0.], dtype=float32)>"
      ]
     },
     "execution_count": 257,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p_mtrx[:,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "82eb95b9-579e-42d6-9e51-05a7cceabd90",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t_mtrx.shape[0] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "eb2bb2dd-9b36-44cd-9cc2-e114064d278c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.04475199317449662"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.random.beta(0.3,0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "91867ff3-3b7b-475d-ac69-77c822f600e6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<function tensorflow.python.ops.random_ops.random_uniform(shape, minval=0, maxval=None, dtype=tf.float32, seed=None, name=None)>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.random.uniform"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f823d4e2-bfb4-4825-89c9-73dc57276323",
   "metadata": {},
   "source": [
    "## Encoder Reenforcement Training Dev"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "id": "ffdfd464-4279-4f89-999e-0d97b2dfcd84",
   "metadata": {},
   "outputs": [],
   "source": [
    "importlib.reload(parser)\n",
    "\n",
    "with open(\"model/semantics/tags.json\", \"r\") as f:\n",
    "    tags = json.load(f)\n",
    "\n",
    "with open(\"model/semantics/predefined_tags.json\", \"r\") as f:\n",
    "    predef = json.load(f)\n",
    "\n",
    "encoder = parser.Encoder(tags, n_limit = 6, predefinitions = predef)\n",
    "\n",
    "with open('fpass_sample.txt', 'r') as f:\n",
    "    examples = f.read().split('\\n')\n",
    "\n",
    "test_batch = main.inBatch(examples[:len(examples)-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "id": "7a26bec1-24c3-437d-9666-800298c47114",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor([[0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1]], shape=(1, 10), dtype=float64)\n",
      "tf.Tensor([0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1], shape=(10,), dtype=float64)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-01-03 23:53:20.825671: W tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: INVALID_ARGUMENT: ConcatOp : Ranks of all input tensors should match: shape[0] = [2,10] vs. shape[1] = [10]\n"
     ]
    },
    {
     "ename": "InvalidArgumentError",
     "evalue": "{{function_node __wrapped__ConcatV2_N_2_device_/job:localhost/replica:0/task:0/device:CPU:0}} ConcatOp : Ranks of all input tensors should match: shape[0] = [2,10] vs. shape[1] = [10] [Op:ConcatV2] name: concat",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[203], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m encoder\u001b[38;5;241m.\u001b[39maddTransition(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m~pad~\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m      2\u001b[0m encoder\u001b[38;5;241m.\u001b[39maddTransition(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m~variable~\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m----> 3\u001b[0m \u001b[43mencoder\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43maddTransition\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m~variable~ -> ~variable~\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Desktop/nova/semantics/parser.py:146\u001b[0m, in \u001b[0;36mEncoder.addTransition\u001b[0;34m(self, tag_seq)\u001b[0m\n\u001b[1;32m    144\u001b[0m     transition \u001b[38;5;241m=\u001b[39m tf\u001b[38;5;241m.\u001b[39mnn\u001b[38;5;241m.\u001b[39msoftmax(logits, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m    145\u001b[0m     \u001b[38;5;28mprint\u001b[39m(transition)\n\u001b[0;32m--> 146\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mTransitionMatrix \u001b[38;5;241m=\u001b[39m \u001b[43mtf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconcat\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mTransitionMatrix\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtransition\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# Update matrix.\u001b[39;00m\n\u001b[1;32m    147\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mTransitionStates[tag_seq] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mTransitionMatrix\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m  \u001b[38;5;66;03m# Record the transition state.\u001b[39;00m\n\u001b[1;32m    148\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m\n",
      "File \u001b[0;32m/usr/local/lib/python3.9/site-packages/tensorflow/python/util/traceback_utils.py:153\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    151\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    152\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[0;32m--> 153\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    154\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m    155\u001b[0m   \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[0;32m/usr/local/lib/python3.9/site-packages/tensorflow/python/framework/ops.py:5983\u001b[0m, in \u001b[0;36mraise_from_not_ok_status\u001b[0;34m(e, name)\u001b[0m\n\u001b[1;32m   5981\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mraise_from_not_ok_status\u001b[39m(e, name) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m NoReturn:\n\u001b[1;32m   5982\u001b[0m   e\u001b[38;5;241m.\u001b[39mmessage \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m (\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m name: \u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mstr\u001b[39m(name \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m))\n\u001b[0;32m-> 5983\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m core\u001b[38;5;241m.\u001b[39m_status_to_exception(e) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "\u001b[0;31mInvalidArgumentError\u001b[0m: {{function_node __wrapped__ConcatV2_N_2_device_/job:localhost/replica:0/task:0/device:CPU:0}} ConcatOp : Ranks of all input tensors should match: shape[0] = [2,10] vs. shape[1] = [10] [Op:ConcatV2] name: concat"
     ]
    }
   ],
   "source": [
    "encoder.addTransition('~pad~')\n",
    "encoder.addTransition('~variable~')\n",
    "encoder.addTransition('~variable~ -> ~variable~')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "id": "b6d60c34-ab7f-474f-be75-f92791635dc8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(2, 10), dtype=float32, numpy=\n",
       "array([[0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1],\n",
       "       [0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1]], dtype=float32)>"
      ]
     },
     "execution_count": 179,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoder.TransitionMatrix"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
